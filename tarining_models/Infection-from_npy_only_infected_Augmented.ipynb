{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "--CLAHE for training\n",
    "--Trying different img sizes\n",
    "--With & without augmentation\n",
    "--Different loss functions \n",
    "--With & without CosineAnnealing\n",
    "--Maybe delete slices without any infection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n",
      "Version:  2.1.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras-segmentation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import cv2 as cv\n",
    "import nibabel as nib\n",
    "import tqdm\n",
    "import gc\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import losses, metrics\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_segmentation as ks\n",
    "\n",
    "os.environ[\"SM_FRAMEWORK\"]=\"tf.keras\"\n",
    "import segmentation_models as sm\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "print(\"Version: \", tf.version.VERSION)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('/home/deeplearning/Documents/DataSets/input/covid19-ct-scans/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define custom learning rate schedule\n",
    "class CosineAnnealingLearningRateSchedule(callbacks.Callback):\n",
    "    # constructor\n",
    "    def __init__(self, n_epochs, n_cycles, lrate_max, verbose=0):\n",
    "        self.epochs = n_epochs\n",
    "        self.cycles = n_cycles\n",
    "        self.lr_max = lrate_max\n",
    "        self.lrates = list()\n",
    " \n",
    "    # calculate learning rate for an epoch\n",
    "    def cosine_annealing(self, epoch, n_epochs, n_cycles, lrate_max):\n",
    "        epochs_per_cycle = np.floor(n_epochs/n_cycles)\n",
    "        cos_inner = (np.pi * (epoch % epochs_per_cycle)) / (epochs_per_cycle)\n",
    "        return lrate_max/2 * (np.cos(cos_inner) + 1)\n",
    " \n",
    "    # calculate and set learning rate at the start of the epoch\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        # calculate learning rate\n",
    "        lr = self.cosine_annealing(epoch, self.epochs, self.cycles, self.lr_max)\n",
    "        # set learning rate\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        # log value\n",
    "        self.lrates.append(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "epochs = 60\n",
    "lrmax = 0.01\n",
    "n_cycles = 5\n",
    "lr_cb = CosineAnnealingLearningRateSchedule(epochs, n_cycles, lrmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 512"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "from scipy.ndimage import distance_transform_edt as distance\n",
    "\n",
    "\n",
    "def calc_dist_map(seg):\n",
    "    res = np.zeros_like(seg)\n",
    "    posmask = seg.numpy().astype(np.bool)\n",
    "    \n",
    "\n",
    "    if np.any(posmask):\n",
    "        negmask = ~posmask\n",
    "        res = distance(negmask) * negmask - (distance(posmask) - 1) * posmask\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def calc_dist_map_batch(y_true):\n",
    "    y_true_numpy = y_true\n",
    "    return np.array([calc_dist_map(y)\n",
    "                     for y in y_true_numpy]).astype(np.float32)\n",
    "\n",
    "\n",
    "def surface_loss_keras(y_true, y_pred):\n",
    "    y_true_dist_map = tf.py_function(func=calc_dist_map_batch,\n",
    "                                     inp=[y_true],\n",
    "                                     Tout=tf.float32)\n",
    "    multipled = y_pred * y_true_dist_map\n",
    "    return K.mean(multipled)\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class AlphaScheduler(Callback):\n",
    "    def init(self, alpha, update_fn):\n",
    "        self.alpha = alpha\n",
    "        self.update_fn = update_fn\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        updated_alpha = self.update_fn(K.get_value(self.alpha))\n",
    "\n",
    "alpha = K.variable(0.5, dtype='float32')\n",
    "\n",
    "def update_alpha(value):\n",
    "    return np.clip(value - 0.01, 0.01, 1)\n",
    "\n",
    "def gl_sl_wrapper(alpha):\n",
    "    def gl_sl(y_true, y_pred):\n",
    "        return alpha* weighted_bce_dice_loss(y_true, y_pred) +  (1-alpha)* surface_loss_keras(y_true, y_pred)\n",
    "    return gl_sl\n",
    "\n",
    "\n",
    "def TverskyLoss(targets, inputs, alpha=0.5, beta=0.5, smooth=1e-6):\n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "       \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        \n",
    "        return 1 - Tversky\n",
    "    \n",
    "def binary_focal_loss(gamma=2., alpha=.25):\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "\n",
    "    return binary_focal_loss_fixed\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "from tensorflow_examples.models.pix2pix import pix2pix\n",
    "def generate_unet_512(img_size=512):\n",
    "    \n",
    "    output_channels = 1      # number of classes on the dataset\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], \n",
    "                                                   include_top=False)\n",
    "    layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "    ]\n",
    "    layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "    # Create the feature extraction model\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "    down_stack.trainable = True\n",
    "\n",
    "    up_stack = [\n",
    "        pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "        pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "        pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "        pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "    ]\n",
    "    inputs = tf.keras.layers.Input(shape=[img_size, img_size, 3])\n",
    "    mid = tf.keras.layers.MaxPooling2D(3, (4,4))(inputs)\n",
    "    x = tf.keras.layers.Conv2D(3, (3,3), padding = 'same')(mid)\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(x)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "    # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "         output_channels, 3, strides=2,\n",
    "         padding='same')(x)  #64x64 -> 128x128\n",
    "    mid = tf.keras.layers.UpSampling2D((4,4))(last)\n",
    "    mid_x = tf.keras.layers.Conv2D(1, (12,12), padding= 'same')(mid)\n",
    "    x = tf.keras.layers.Conv2D(1, (3,3), padding= 'same')(mid_x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "att_res_model = generate_unet_512()\n",
    "att_res_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'strategy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-691662215a53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0matt_res_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFPN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resnet34'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Model_1 = cts_model((img_size, img_size, 1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'strategy' is not defined"
     ]
    }
   ],
   "source": [
    "from Models import Attention_ResUNet, UNet, Attention_UNet\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "with strategy.scope():\n",
    "    att_res_model = sm.FPN('resnet34', encoder_weights=None, input_shape=(512, 512, 2), classes=1, activation='sigmoid')\n",
    "    #Model_1 = cts_model((img_size, img_size, 1))\n",
    "    #att_res_model = Attention_ResUNet((img_size, img_size, 1), dropout_rate=0.3)\n",
    "#     att_res_model = generate_unet_512()\n",
    "    dice_loss = sm.losses.DiceLoss()\n",
    "    focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "    total_loss = dice_loss + (1 * focal_loss)\n",
    "    metrics = [sm.metrics.IOUScore(), sm.metrics.FScore()]\n",
    "    #att_res_model.compile(optimizer=optimizers.Adam(lr = 1e-2), loss=TverskyLoss, metrics=[ tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "    att_res_model.compile(optimizer=optimizers.Adam(lr = 1e-2), loss=tf.keras.losses.BinaryCrossentropy(), metrics=metrics)\n",
    "#att_res_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(Model_1, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_fpath = \"Modelsss/Test_best.hdf5\"\n",
    "cts_checkpoint_cb = callbacks.ModelCheckpoint(checkpoint_fpath, \n",
    "                                              monitor='val_iou_score', \n",
    "                                              save_best_only=True, \n",
    "                                              mode='max', \n",
    "                                              verbose=1,\n",
    "                                              save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hu(Test):\n",
    "        image = Test.pixel_array.astype(np.int16)\n",
    "\n",
    "        intercept = Test.RescaleIntercept\n",
    "        slope = Test.RescaleSlope\n",
    "\n",
    "        if slope != 1:\n",
    "            image = slope * image.astype(np.float64)\n",
    "            image = image.astype(np.int16)\n",
    "\n",
    "        image += np.int16(intercept)\n",
    "\n",
    "        return np.array(image, dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydicom import dcmread\n",
    "# directory='/home/deeplearning/Documents/DataSets/COD0001'\n",
    "directory='/home/deeplearning/Documents/DataSets/Patch-Test'\n",
    "patients = os.listdir(directory)\n",
    "patients.sort(key= lambda x: (len (x), x))\n",
    "    \n",
    "while patients[0][0]=='.':\n",
    "    del patients[0]\n",
    "        \n",
    "Slices = [dcmread(directory + '/' + s, force=True) for s in patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='/home/deeplearning/Documents/DataSets/npy/Augmented_norm_every_slice_fixed/image/'\n",
    "mask_path='/home/deeplearning/Documents/DataSets/npy/Augmented_norm_every_slice_fixed/mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set=train_test_split(os.listdir(image_path), test_size = 0.10, random_state = 0)\n",
    "train_set, val_set=train_test_split(train_set, test_size = 0.11, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clahe = cv.createCLAHE(clipLimit=3.0)\n",
    "\n",
    "def norm(CT):\n",
    "    norm_data = (CT)/(255)\n",
    "    return norm_data\n",
    "\n",
    "def normalize(CT):\n",
    "    Min=-1000\n",
    "    Max=400\n",
    "    CT=np.clip(CT, Min, Max)\n",
    "    norm_data = (CT-Min)/(Max-Min)\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Generator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, images, masks, batch_size=32):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.images = images\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(len(self.images) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        IDs = self.images[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "#         image_set=np.array([np.load(image_path + ID) for ID in IDs])\n",
    "#         image_set=np.array([np.repeat(np.load(image_path + ID), 3, axis=-1) for ID in IDs])\n",
    "        image_set=[np.repeat(np.load(image_path + ID), 2, axis=-1) for ID in IDs]\n",
    "#         image_set=np.array([norm(clahe.apply(np.uint8(np.load(image_path + ID)*255))) for ID in IDs])\n",
    "        \n",
    "        for raw in image_set:\n",
    "            raw[...,1]= norm(clahe.apply(np.uint8(raw[...,1]*255)))\n",
    "\n",
    "\n",
    "            \n",
    "        image_set = np.array(image_set)\n",
    "        \n",
    "        mask_set=np.array([np.load(mask_path + ID) for ID in IDs])\n",
    "#         mask_set=np.array([tf.keras.utils.to_categorical(np.load(mask_path + ID), num_classes=4) for ID in IDs])\n",
    "#         mask_set=np.array([tf.keras.utils.to_categorical(np.where(np.load(mask_path + ID)==3, 2, np.load(mask_path + ID)), num_classes=3) for ID in IDs])\n",
    "        \n",
    "        return image_set, mask_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator=Custom_Generator(train_set, train_set, batch_size=batch_size)\n",
    "val_generator=Custom_Generator(val_set, val_set, batch_size=batch_size)\n",
    "test_generator=Custom_Generator(test_set, test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "ctsRes = att_res_model.fit(train_generator, \n",
    "                       steps_per_epoch= int(len(train_set) / batch_size), \n",
    "                       epochs=epochs,\n",
    "                       verbose=1,\n",
    "                       validation_data=val_generator,\n",
    "                        validation_steps=int(len(val_set) / batch_size),\n",
    "                        validation_freq=1,\n",
    "                        callbacks = [cts_checkpoint_cb, lr_cb]\n",
    "                       )\n",
    "    \n",
    "att_res_model.save('Modelsss/Test.h5')\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "fig, axes = plt.subplots(1, 1, figsize=(11,5))\n",
    "axes.plot(ctsRes.history['loss'], color='b', label='train-loss')\n",
    "axes.plot(ctsRes.history['val_loss'], color='m', label='valid-loss')\n",
    "axes.plot(ctsRes.history['iou_score'], color='y', label='iou_score')\n",
    "axes.plot(ctsRes.history['val_iou_score'], color='r', label='val_iou_score')\n",
    "axes.set_ylabel('loss')\n",
    "axes.set_xlabel('epoch')\n",
    "axes.set_ylim([0,1])\n",
    "axes.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "att_res_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "att_res_model.load_weights(checkpoint_fpath)\n",
    "att_res_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Test_model= tf.keras.models.clone_model(\n",
    "    att_res_model, input_tensors=None, clone_function=None)\n",
    "Test_model.load_weights(checkpoint_fpath)\n",
    "Test_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test=np.load(image_path+'100.npy')\n",
    "print(Test.shape)\n",
    "len(np.unique(Test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Test)\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test=np.repeat(Test, 3, axis=-1)\n",
    "Test = clahe.apply(np.uint8(Test*255))\n",
    "plt.imshow(Test, cmap='gray')\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "import cv2 as cv\n",
    "from skimage.morphology import disk,erosion, dilation, opening, closing\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "end_check = False\n",
    "\n",
    "Test_size=5\n",
    "for i in range(15):\n",
    "    \n",
    "    if (i+1)*Test_size > len(Slices):\n",
    "        Test=Slices[i*Test_size:]\n",
    "        end_check = True\n",
    "        \n",
    "    else:\n",
    "        Test=Slices[i*Test_size:(i+1)*Test_size]\n",
    "    \n",
    "    for ii in range(len(Test)):\n",
    "#         Test[ii]=cv.resize(normalize(get_hu(Test[ii])), dsize = (img_size, img_size),interpolation = cv.INTER_AREA).astype('float32')\n",
    "        Test[ii]=normalize(get_hu(Test[ii]))#.astype('float32')\n",
    "        Test[ii]=np.expand_dims(Test[ii], -1)\n",
    "        Test[ii]=np.repeat(Test[ii],2,-1)\n",
    "        Test[ii][...,1]=norm(clahe.apply(np.uint8(Test[ii][...,1]*255)))\n",
    "    \n",
    "    \n",
    "    Test = np.asarray(Test)\n",
    "    infection_pred=att_res_model.predict(Test)\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(2, Test.shape[0], figsize=(24,9))\n",
    "    for iii in range(Test.shape[0]):\n",
    "        \n",
    "        axes[0,iii].imshow(np.squeeze(Test[iii,...,0]), cmap='gray')\n",
    "        axes[0,iii].set_title('Original CT')\n",
    "        axes[0,iii].set_xticks([]); axes[0,iii].set_yticks([])\n",
    "\n",
    "        axes[1,iii].imshow(np.squeeze(Test[iii,...,0]), cmap='gray')\n",
    "#         axes[1,iii].imshow(np.squeeze(np.argmax(infection_pred[iii,...], axis= -1)), alpha=0.7)\n",
    "        axes[1,iii].imshow(np.where(np.squeeze(infection_pred[iii,...])<0.1,0,1), alpha=0.7)\n",
    "\n",
    "        axes[1,iii].set_title('Predicted infection')\n",
    "        axes[1,iii].set_xticks([]); axes[1,iii].set_yticks([])\n",
    "        \n",
    "    plt.show()\n",
    "    print('\\n \\n ################################################################################################')\n",
    "    print(' ################################################################################################\\n \\n \\n')\n",
    "    \n",
    "    if end_check:\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ctsRes = att_res_model.fit(train_generator, \n",
    "                       steps_per_epoch= int(len(train_set) / batch_size), \n",
    "                       epochs=epochs,\n",
    "                       verbose=1,\n",
    "                       validation_data=val_generator,\n",
    "                        validation_steps=int(len(val_set) / batch_size),\n",
    "                        validation_freq=1,\n",
    "                        callbacks = [cts_checkpoint_cb, lr_cb]\n",
    "                       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
